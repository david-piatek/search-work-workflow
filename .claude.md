# Job Scraper Application - Documentation Projet

## Vue d'ensemble

Application de scraping d'offres d'emploi avec architecture moderne:
- Frontend: Vite + Svelte
- Backend: NestJS + TypeORM + Bull Queue
- Infrastructure: Docker, Kubernetes, Helm, ArgoCD
- Automation: Workflow n8n avec backup GitHub

## Architecture

### Backend (NestJS)

**Modules:**
- `scrapers`: Gestion et génération dynamique de scrapers
- `jobs`: Stockage et récupération des offres scrapées

**Services clés:**
- `ScraperGeneratorService`: Génère le code des scrapers automatiquement
- `ScraperExecutorService`: Exécute les scrapers et sauvegarde les résultats
- `ScraperProcessor`: Traite les jobs de scraping via Bull Queue

**Technologies:**
- TypeORM pour PostgreSQL
- Bull pour les queues Redis
- Puppeteer + Cheerio pour le scraping
- Swagger pour la documentation API

### Frontend (Svelte)

**Composants principaux:**
- `ScraperSelector`: Sélection et création de scrapers
- `JobsList`: Affichage des résultats scrapés
- `Stats`: Dashboard de statistiques

**Features:**
- API client avec Axios
- Storybook pour documentation composants
- Tests E2E avec Playwright

### Infrastructure

**Docker Compose:**
- PostgreSQL 16
- Redis 7
- Backend NestJS
- Frontend Svelte/Nginx

**Kubernetes (Helm):**
- Deployments: backend, frontend
- StatefulSets: postgres, redis
- Services, Ingress, PVC
- HPA (optionnel)

**ArgoCD:**
- GitOps pour déploiement automatique
- Sync automatique des changements
- Health checks et rollbacks

### Workflow n8n

Pipeline automatisé:
1. Schedule (cron toutes les 6h)
2. Récupération des scrapers
3. Exécution séquentielle
4. Sauvegarde JSON locale
5. Backup GitHub dans `/backup`
6. Notification Slack

## Standards Appliqués

### Structure Monorepo

```
apps/
  backend/        # NestJS API
  frontend/       # Svelte SPA
cloud/
  docker/         # Docker Compose et Dockerfiles
  helm/           # Kubernetes charts
  argocd/         # GitOps config
n8n/              # Workflow automation
```

### Docker

- Multi-stage builds pour optimisation
- Images Alpine pour légèreté
- Health checks configurés
- Volumes pour persistence
- Utilisation de `docker compose` (v2) au lieu de `docker-compose`
- Centralisation dans `cloud/docker/`

### Helm Charts

- Templates modulaires
- Values pour différents environnements
- Secrets management
- Resource limits/requests
- Probes (liveness/readiness)

### Taskfile

Commandes standardisées:
- `dev`: Développement
- `build`: Build production
- `test`: Tests (unit + e2e)
- `lint`: Linting
- `docker:*`: Gestion Docker
- `helm:*`: Déploiement K8s

### Tests

**Backend:**
- Tests unitaires: Jest
- Tests e2e: Supertest
- Coverage configuré

**Frontend:**
- Tests unitaires: Vitest
- Tests e2e: Playwright
- Tests composants: Storybook

### Git Hooks

- **pre-commit**: lint-staged
  - Prettier
  - ESLint

- **pre-push**:
  - Tous les tests

### Outils d'Analyse

- **Swagger**: Documentation API auto-générée
- **Storybook**: Catalogue de composants UI
- **TypeScript**: Typage strict
- **ESLint + Prettier**: Code quality

## Fonctionnement

### Génération Dynamique de Scrapers

1. Frontend envoie nom + URL du site
2. Backend vérifie si scraper existe en DB
3. Si non, `ScraperGeneratorService` génère le code
4. Code générique avec sélecteurs CSS communs
5. Sauvegarde en DB avec metadata
6. Retour du scraper au frontend

### Exécution de Scraping

1. Frontend demande exécution
2. Backend ajoute job à la queue Redis
3. `ScraperProcessor` récupère le job
4. Exécution du code scraper (Puppeteer)
5. Parsing HTML avec Cheerio
6. Sauvegarde JSON + PostgreSQL
7. Mise à jour stats d'exécution

### Déploiement GitOps

1. Push vers GitHub
2. ArgoCD détecte changement
3. Sync automatique Helm chart
4. Rollout K8s progressif
5. Health checks
6. Rollback automatique si erreur

### Workflow n8n

1. Trigger schedule (cron)
2. GET `/scrapers` → liste
3. Pour chaque scraper:
   - POST `/scrapers/execute`
   - Wait 30s
   - GET `/jobs?source={scraper}`
4. Save JSON local + GitHub
5. Notification Slack

## Configuration Environnements

### Développement

```bash
task dev
# Frontend: localhost:5173
# Backend: localhost:3000
# Swagger: localhost:3000/api
```

### Docker Local

```bash
task docker:up
# Avec PostgreSQL + Redis
```

### Production K8s

```bash
# Via Helm
task helm:install

# Via ArgoCD (GitOps)
kubectl apply -f argocd/application.yaml
```

## Points d'Attention

### Sécurité

- Secrets en K8s Secrets (pas en values.yaml plain)
- CORS configuré sur backend
- Validation des inputs (class-validator)
- Rate limiting recommandé (production)

### Performance

- Bull Queue pour async processing
- Redis cache
- Index DB sur colonnes fréquentes
- HPA pour scaling automatique

### Monitoring

- Logs structurés (JSON)
- Health endpoints (`/api`)
- Prometheus metrics (à ajouter)
- Grafana dashboards (à ajouter)

### Backup

- Données jobs en PostgreSQL
- Fichiers JSON en PVC K8s
- Backup GitHub via n8n
- Snapshots DB recommandés

## Prochaines Étapes

1. Ajouter plus de scrapers prédéfinis
2. Améliorer génération automatique (IA)
3. Implémenter authentification API
4. Ajouter métriques Prometheus
5. CI/CD pipeline (GitHub Actions)
6. Documentation utilisateur détaillée
7. Tests de charge
8. Monitoring avancé (Datadog/New Relic)

## Commandes Utiles

```bash
# Dev
task dev

# Tests
task test

# Build
task build

# Docker
task docker:build
task docker:up

# K8s
task helm:install
kubectl get pods -n job-scraper

# Logs
task docker:logs
kubectl logs -n job-scraper -l app=backend -f

# Storybook
task storybook

# Swagger
open http://localhost:3000/api
```

## Technologies Complètes

**Frontend:**
- Svelte 4
- Vite 5
- Axios
- Storybook 7
- Playwright
- Vitest

**Backend:**
- NestJS 10
- TypeORM
- Bull
- Puppeteer
- Cheerio
- Swagger
- Jest

**Infrastructure:**
- Docker & Docker Compose
- Kubernetes
- Helm 3
- ArgoCD
- n8n
- PostgreSQL 16
- Redis 7

**DevOps:**
- Task (go-task)
- Husky
- lint-staged
- Prettier
- ESLint

## Organisation Cloud

L'ensemble des ressources cloud est centralisé dans le répertoire `cloud/`:

- **`cloud/docker/`**:
  - `compose.yaml` (v2 naming convention)
  - `Dockerfile.backend`
  - `Dockerfile.frontend`

- **`cloud/helm/`**:
  - Charts Kubernetes pour déploiement

- **`cloud/argocd/`**:
  - Configuration GitOps

### Conventions

- Utiliser `docker compose` (v2) au lieu de `docker-compose` (v1)
- Fichier nommé `compose.yaml` (convention moderne) au lieu de `docker-compose.yml`
- Paths relatifs depuis la racine du projet
- Centralisation cloud pour faciliter la maintenance

## Dernière Mise à Jour

Date: 2025-12-03
Version: 1.1.0
Status: Projet complet et fonctionnel avec structure cloud organisée
